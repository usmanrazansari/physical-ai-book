"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[179],{2420(a){a.exports=JSON.parse('{"label":"ai","permalink":"/physical-ai-book/docs/tags/ai","allTagsPath":"/physical-ai-book/docs/tags","count":4,"items":[{"id":"module-4-vla/ch2-capstone-autonomous-humanoid","title":"Capstone: Autonomous Humanoid System Integration","description":"Integration of all previous concepts into a complete autonomous humanoid system demonstrating the full application of physical AI concepts","permalink":"/physical-ai-book/docs/module-4-vla/ch2-capstone-autonomous-humanoid"},{"id":"module-3-ai-robot-brain/ch2-isaac-ros-vslam-nav2","title":"Isaac ROS, VSLAM, and Nav2 Navigation","description":"Understanding NVIDIA Isaac ROS integration, Visual SLAM, and Nav2 navigation systems for autonomous robotic movement","permalink":"/physical-ai-book/docs/module-3-ai-robot-brain/ch2-isaac-ros-vslam-nav2"},{"id":"module-3-ai-robot-brain/ch1-isaac-sim-synthetic-data","title":"Isaac Sim and Synthetic Data Generation","description":"Understanding NVIDIA Isaac Sim for generating synthetic data to train AI models for robotic applications","permalink":"/physical-ai-book/docs/module-3-ai-robot-brain/ch1-isaac-sim-synthetic-data"},{"id":"module-4-vla/ch1-voice-to-action-llm-planning","title":"Voice-to-Action and LLM Planning","description":"Understanding how voice commands are converted to robotic actions through Large Language Model planning in Vision-Language-Action systems","permalink":"/physical-ai-book/docs/module-4-vla/ch1-voice-to-action-llm-planning"}],"unlisted":false}')}}]);