"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[3601],{4286(e,n,o){o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>a,metadata:()=>l,toc:()=>r});var i=o(4848),t=o(8453);const a={title:"Module 4: Vision-Language-Action (VLA)",description:"Voice-to-action systems with LLM planning and the capstone autonomous humanoid system integrating all previous concepts",sidebar_label:"Module 4: Vision-Language-Action",slug:"/module-4-vla"},s="Module 4: Vision-Language-Action (VLA)",l={id:"module-4-vla/index",title:"Module 4: Vision-Language-Action (VLA)",description:"Voice-to-action systems with LLM planning and the capstone autonomous humanoid system integrating all previous concepts",source:"@site/docs/module-4-vla/index.md",sourceDirName:"module-4-vla",slug:"/module-4-vla",permalink:"/physical-ai-book/docs/module-4-vla",draft:!1,unlisted:!1,editUrl:"https://github.com/your-username/physical-ai-book/tree/main/docs/module-4-vla/index.md",tags:[],version:"current",frontMatter:{title:"Module 4: Vision-Language-Action (VLA)",description:"Voice-to-action systems with LLM planning and the capstone autonomous humanoid system integrating all previous concepts",sidebar_label:"Module 4: Vision-Language-Action",slug:"/module-4-vla"},sidebar:"tutorialSidebar",previous:{title:"Isaac ROS, VSLAM, and Nav2 Navigation",permalink:"/physical-ai-book/docs/module-3-ai-robot-brain/ch2-isaac-ros-vslam-nav2"},next:{title:"Voice-to-Action and LLM Planning",permalink:"/physical-ai-book/docs/module-4-vla/ch1-voice-to-action-llm-planning"}},c={},r=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Module Structure",id:"module-structure",level:2}];function u(e){const n={a:"a",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"module-4-vision-language-action-vla",children:"Module 4: Vision-Language-Action (VLA)"}),"\n",(0,i.jsx)(n.p,{children:"This module explores the cutting-edge intersection of vision, language, and action in robotics, representing the most advanced form of human-robot interaction. VLA systems enable robots to understand natural language commands and execute complex tasks in physical environments."}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Vision-Language-Action represents the frontier of robotics research, where robots can understand human language, perceive their environment visually, and execute appropriate actions. This module covers:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Voice-to-action systems and their implementation"}),"\n",(0,i.jsx)(n.li,{children:"Large Language Model (LLM) planning for robotic tasks"}),"\n",(0,i.jsx)(n.li,{children:"Integration of all previous concepts into a complete autonomous humanoid system"}),"\n",(0,i.jsx)(n.li,{children:"The capstone application of all concepts learned throughout the book"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this module, you will understand:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"How voice commands are processed and converted to robotic actions"}),"\n",(0,i.jsx)(n.li,{children:"The role of LLMs in planning robotic behaviors"}),"\n",(0,i.jsx)(n.li,{children:"How to integrate multiple robotics subsystems into a cohesive system"}),"\n",(0,i.jsx)(n.li,{children:"The challenges and solutions in creating autonomous humanoid robots"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"module-structure",children:"Module Structure"}),"\n",(0,i.jsx)(n.p,{children:"This module contains two chapters:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/physical-ai-book/docs/module-4-vla/ch1-voice-to-action-llm-planning",children:"Voice-to-Action and LLM Planning"})," - Natural language processing for robotics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/physical-ai-book/docs/module-4-vla/ch2-capstone-autonomous-humanoid",children:"Capstone: Autonomous Humanoid System"})," - Integration of all concepts into a complete system"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This module serves as the culmination of all concepts introduced in previous modules, demonstrating their integration in a sophisticated robotic application."})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},8453(e,n,o){o.d(n,{R:()=>s,x:()=>l});var i=o(6540);const t={},a=i.createContext(t);function s(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);